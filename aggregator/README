Reference Aggregator README

1. Aptitude packages

   * IF using postgres
      (1) sudo apt-get install postgresql python-psycopg2
   * IF using mysql
      (1) sudo apt-get install mysql-server mysql-client python-mysqldb

    (2) sudo apt-get install python-requests 	
   

2a. PostgreSQL Configuration

   We use <AGGREGATOR_OPERATOR_NAME>=agguser, but any name you like
   should work.

    Omit (1) if you already have a postgres user
    (1) sudo -u postgres psql -c '\password postgres' postgres
    (2) sudo -u postgres createuser --no-createdb --no-createrole \
          --no-superuser <AGGREGATOR_OPERATOR_NAME>
    (3) sudo -u postgres psql -c '\password <AGGREGATOR_OPERATOR_NAME>' postgres
    (4) sudo -u postgres createdb --owner=<AGGREGATOR_OPERATOR_NAME> aggregator

2b. MySQL Configuration

    (1) echo "CREATE DATABASE aggregator" | mysql -u root -p
    (2) echo "GRANT ALL ON aggregator.* TO <AGGREGATOR_OPERATOR_NAME>@localhost IDENTIFIED BY '<AGGREGATOR_PASSWORD>'" | mysql -u root -p

3. Configuring the aggregator to point to local datastore(s)

   (1) Query the current config store in a web-browser:
   http://tamassos.gpolab.bbn.com/info/opsconfig/geni-prod

   Inspect the output and find the href(s) of the local datastore(s)
   you are interested in querying.

   (2) Open the file 'config/collector_operator.conf'.
   Under the [main] section add the json-style dictionaries to the
   datastores_dict item in the format:
   "<aggregate_id>":"<local_datastore_url_for_info_queries>"

   As an example,
   The href, "http://tamassos.gpolab.bbn.com/info/gpo-ig", translates to
   {"gpo-ig":"http://tamassos.gpolab.bbn.com/info/"}

4. Aggregator programs:

   The datastores_dict item in '/config/collector_operator.conf' is
   the collection of local datastores to be queried.  Use these to
   form arguments in the execution of the aggregator programs.

   (1) single_local_datastore_info_crawler.py performs information
   fetching. It puts data in the aggregator database.  It needs to be
   called with three arguments:

     -b or --baseurl with <url_of_info_url> 
        This starts with "http://" and the convention is to end with "/info"
     -a or --aggregateid with aggregate_id at -b's datastore (i.e., gpo-ig)
     -o or --object-types with letters of object types to get info on
     	n: for node
	i: for interface
	s: for sliver
	l: for link
	v: for vlan
	So argument -o nislv will get information on all object types
     -d or --debug will print what would be added to the aggregator database
        to the screen and does not add anything to the database
     -h or --help prints the usage() function, repeat of this info
   
   
   (2) single_local_datastore_object_type_fetcher.py does a single fetch
   of timeseries data. It needs to be called with two arguments:

     -a or --aggregateid of the aggregate in the ops_aggregate table
     -o or --object-type of object to get (note singularity). Valid object 
        types are (only one is passed, unlike the info_crawler above):
	n: for node
	i: for interface
	So argument -o n will get ts data for all node events and all nodes
	at the datastore
     -d or --debug will print what would be added to the aggregator database
        to the screen and does not add anything to the database
     -h or --help prints the usage() function, repeat of this info

   (3) Running these programs as cron jobs.

    Go into crontab:

    crontab -e

    Add the jobs you wish to run; examples are below.  In the first
    example, the info crawler is run once per day at 11:30pm.  It
    fetches objects of type n and i (-o ni).  Substitute the
    aggregate_id and url of the datastore you wish to aggregate data
    from.
    
    In the last two examples, the data fetchers nodes (-o n) and
    interfaces (-o i) runs every 5 minutes.  Substitute the
    aggregate_id the same as for the info crawler. Save and exit
    crontab.

    30 23 * * * (cd /usr/local/ops-monitoring/aggregator; python single_local_datastore_info_crawler.py -b http://tamassos.gpolab.bbn.com/info/ -a gpo-ig -o ni)

    */5 * * * * (cd /usr/local/ops-monitoring/aggregator; python single_local_datastore_object_type_fetcher.py -a gpo-ig -o n)

    */5 * * * * (cd /usr/local/ops-monitoring/aggregator; python single_local_datastore_object_type_fetcher.py -a gpo-ig -o i)

5. Query Library

   The query library is used by services that sit on top of the aggregator.
   The query library is currently contained in the aggregator module under
   the file psql_queries.py.  This file should be installed under 
   /usr/local/lib/ at this time.
